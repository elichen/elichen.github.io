{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "763985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd73ef3-8adc-4622-8718-fe47f6ecd473",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting self-play training...\n",
      "\n",
      "Episode 0/10000 (2.9s)\n",
      "Steps: 1000\n",
      "P1: reward=-1.53\n",
      "P2: reward=1.31\n",
      "ε=0.88\n",
      "Buffer size: 2000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 1/10000 (3.3s)\n",
      "Steps: 1000\n",
      "P1: reward=-1.00\n",
      "P2: reward=1.47\n",
      "ε=0.78\n",
      "Buffer size: 4000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 2/10000 (4.3s)\n",
      "Steps: 1000\n",
      "P1: reward=-27.03\n",
      "P2: reward=-1.30\n",
      "ε=0.69\n",
      "Buffer size: 6000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 3/10000 (5.8s)\n",
      "Steps: 1000\n",
      "P1: reward=-2.80\n",
      "P2: reward=4.92\n",
      "ε=0.61\n",
      "Buffer size: 8000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 4/10000 (6.4s)\n",
      "Steps: 1000\n",
      "P1: reward=-1.27\n",
      "P2: reward=0.75\n",
      "ε=0.54\n",
      "Buffer size: 10000\n",
      "----------------------------------------\n",
      "Player 1 hit the puck! Velocity: 4.6\n",
      "\n",
      "Episode 5/10000 (7.4s)\n",
      "Steps: 1000\n",
      "P1: reward=-2.19\n",
      "P2: reward=0.51\n",
      "ε=0.47\n",
      "Buffer size: 12000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 6/10000 (8.2s)\n",
      "Steps: 1000\n",
      "P1: reward=1.01\n",
      "P2: reward=-1.63\n",
      "ε=0.42\n",
      "Buffer size: 14000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 7/10000 (9.0s)\n",
      "Steps: 1000\n",
      "P1: reward=-2.25\n",
      "P2: reward=2.66\n",
      "ε=0.37\n",
      "Buffer size: 16000\n",
      "----------------------------------------\n",
      "Player 1 hit the puck! Velocity: 4.5\n",
      "\n",
      "Episode 8/10000 (9.5s)\n",
      "Steps: 1000\n",
      "P1: reward=-1.40\n",
      "P2: reward=0.15\n",
      "ε=0.33\n",
      "Buffer size: 18000\n",
      "----------------------------------------\n",
      "\n",
      "Episode 9/10000 (9.6s)\n",
      "Steps: 1000\n",
      "P1: reward=-0.46\n",
      "P2: reward=0.05\n",
      "ε=0.29\n",
      "Buffer size: 20000\n",
      "----------------------------------------\n",
      "Player 0 hit the puck! Velocity: 4.5\n",
      "Player 0 hit the puck! Velocity: 6.6\n"
     ]
    }
   ],
   "source": [
    "# Example notebook usage\n",
    "from train import AirHockeyEnv, train_agent\n",
    "\n",
    "# Create environment\n",
    "env = AirHockeyEnv()\n",
    "\n",
    "# Train agent with plotting\n",
    "trained_agent, training_metrics = train_agent(env, plot=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = \"air_hockey_model\"\n",
    "trained_agent.online_network.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
