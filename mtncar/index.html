<!DOCTYPE html>
<html>
<head>
    <title>Mountain Car</title>
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="src/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0"></script>
</head>
<body>
    <div class="container">
        <div class="instructions">
            <h2>Mountain Car</h2>
            <p id="modeText">Watch a pre-trained AI agent solve this classic control problem!</p>
            <p style="font-size: 14px; margin-top: 5px;">Goal: Reach the flag on the right peak</p>
        </div>
        <canvas id="gameCanvas"></canvas>
        <div class="training-info">
            <h3>About This Model</h3>
            <p>
                This agent was trained using <strong>Deep Q-Network (DQN)</strong> with
                <a href="https://stable-baselines3.readthedocs.io/" target="_blank">Stable Baselines3</a>,
                a state-of-the-art reinforcement learning library in Python. The trained model was then converted
                to TensorFlow.js to run directly in your browser.
            </p>

            <h4>Training Details</h4>
            <ul>
                <li><strong>Algorithm:</strong> DQN (Deep Q-Network)</li>
                <li><strong>Training Duration:</strong> 300,000 timesteps (~90 seconds on CPU)</li>
                <li><strong>Network Architecture:</strong> 2 inputs → [64, 64] hidden → 3 actions</li>
                <li><strong>Best Performance:</strong> Achieved at 75,000 steps with mean reward of 114</li>
                <li><strong>Episode Length:</strong> Typically solves in 100-200 steps (vs 1000 max)</li>
                <li><strong>Success Rate:</strong> ~100% after convergence</li>
            </ul>

            <h4>How It Learned</h4>
            <p>
                The agent learned through trial and error, receiving rewards for:
            </p>
            <ul>
                <li><strong>Height gain:</strong> +10 points per unit of elevation increase</li>
                <li><strong>Velocity toward goal:</strong> +5 points for moving in the right direction</li>
                <li><strong>Reaching the goal:</strong> +100 points (success!)</li>
                <li><strong>Action efficiency:</strong> -0.1 points for using the engine</li>
            </ul>
            <p>
                Through millions of interactions, it discovered the optimal strategy: build momentum by
                rocking back and forth, then use that energy to reach the goal.
            </p>

            <h4>Technical Implementation</h4>
            <ul>
                <li><strong>Training Framework:</strong> PyTorch + Stable Baselines3</li>
                <li><strong>Inference Framework:</strong> TensorFlow.js (browser)</li>
                <li><strong>Model Size:</strong> 143 KB (compressed weights)</li>
                <li><strong>Conversion Accuracy:</strong> &lt;0.000002 error vs original model</li>
            </ul>

            <p style="margin-top: 20px; font-size: 14px;">
                <strong>View the code:</strong><br>
                <a href="mtncar_env.py" target="_blank">Custom Gym Environment</a> |
                <a href="train_sb3.py" target="_blank">Training Script</a> |
                <a href="convert_to_tfjs.py" target="_blank">Model Converter</a> |
                <a href="src/sb3Model.js" target="_blank">Browser Inference Code</a>
            </p>
        </div>
    </div>
    <script src="src/mountainCar.js"></script>
    <script src="src/mountainCarEnv.js"></script>
    <script src="src/utils.js"></script>
    <script src="src/sb3Model.js"></script>
    <script src="src/game.js"></script>
    <script>
        let game;

        async function init() {
            await tf.setBackend('cpu');
            game = new Game();
        }

        init();
    </script>
</body>
</html> 